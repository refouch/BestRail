{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API SNCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaschen/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requeter l'api SNCF pour avoir les datasets en GTFS\n",
    "\n",
    "SOURCES = {\n",
    "    \"SNCF_NATIONAL\": \"https://eu.ftp.opendatasoft.com/sncf/plandata/Export_OpenData_SNCF_GTFS_NewTripId.zip\",\n",
    "    \"TRANSILIEN\": \"https://eu.ftp.opendatasoft.com/sncf/gtfs/transilien-gtfs.zip\"\n",
    "}\n",
    "\n",
    "dir = \"donnees_gtfs\"\n",
    "\n",
    "def download_and_extract_gtfs(name, url):\n",
    "  \n",
    "    path = os.path.join(dir, name)\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status() \n",
    "\n",
    "        # Suppression des anciennes données\n",
    "        if os.path.exists(path):\n",
    "            shutil.rmtree(path)\n",
    "        os.makedirs(path)\n",
    "\n",
    "        with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "            z.extractall(path)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du traitement de {name} : {e}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Création du dossier racine si inexistant\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "    for name, url in SOURCES.items():\n",
    "        download_and_extract_gtfs(name, url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temps de parcours entre gares (IDH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_IDH = \"https://eu.ftp.opendatasoft.com/sncf/prr/temps_correspondance/INFOTRAINS_Export_IDH.zip\"\n",
    "dir_idh = \"donnees_idh\"\n",
    "\n",
    "def update_idh_data():\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(URL_IDH, timeout=60)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        if os.path.exists(dir_idh):\n",
    "            shutil.rmtree(dir_idh)\n",
    "        os.makedirs(dir_idh)\n",
    "\n",
    "\n",
    "        with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "            z.extractall(dir_idh)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur : {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    update_idh_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
